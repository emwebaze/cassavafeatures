{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data to format usable by Keras\n",
    "Given a folder `raw_data` containing several subfolders each representing a class of images, process the folder to another folder with `train, test, validation` as subfolders and split the images according to some percentages into these separate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = './data/'\n",
    "base_dir = './pdata/'\n",
    "train = os.path.join(base_dir, 'train')\n",
    "test = os.path.join(base_dir, 'test')\n",
    "validation = os.path.join(base_dir, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create directories\n",
    "dirs = [base_dir, train, test, validation]\n",
    "for directory in dirs:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = [cls for cls in os.listdir(raw_data) if not cls.startswith('.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make class directories\n",
    "for cls in classes:\n",
    "    for directory in [train, test, validation]:\n",
    "        cls_path = os.path.join(directory, cls)\n",
    "        if not os.path.exists(cls_path):\n",
    "            os.makedirs(cls_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 49 training images for class cgm\n",
      "processed 19 test images for class cgm\n",
      "processed 30 validation images for class cgm\n",
      "processed 65 training images for class cmd\n",
      "processed 26 test images for class cmd\n",
      "processed 40 validation images for class cmd\n",
      "processed 58 training images for class healthy\n",
      "processed 23 test images for class healthy\n",
      "processed 35 validation images for class healthy\n",
      "processed 36 training images for class cbb\n",
      "processed 14 test images for class cbb\n",
      "processed 22 validation images for class cbb\n",
      "processed 60 training images for class cbsd\n",
      "processed 24 test images for class cbsd\n",
      "processed 36 validation images for class cbsd\n",
      "Training examples = 268, Testing examples = 106, Validation examples = 163\n"
     ]
    }
   ],
   "source": [
    "training, testing = .5, .2\n",
    "num_training_examples = 0\n",
    "num_test_examples = 0\n",
    "num_validation_examples = 0\n",
    "\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(raw_data, cls)\n",
    "    imgs = os.listdir(cls_path)\n",
    "    np.random.shuffle(imgs)\n",
    "    trainidx = np.int(len(imgs) * training)\n",
    "    testidx = trainidx + np.int(len(imgs) * testing)\n",
    "    train_set = imgs[:trainidx]\n",
    "    test_set = imgs[trainidx:testidx]\n",
    "    validation_set = imgs[testidx:]\n",
    "    for i,img in enumerate(train_set):\n",
    "        imgpath = os.path.join(cls_path, img)\n",
    "        topath = os.path.join(train, cls, cls+'.'+str(i)+img[-4:])\n",
    "        shutil.copyfile(imgpath, topath)\n",
    "    num_training_examples += len(train_set)\n",
    "    print(\"processed %s training images for class %s\"%(len(train_set), cls))\n",
    "    \n",
    "    #Process test data\n",
    "    for i,img in enumerate(test_set):\n",
    "        imgpath = os.path.join(cls_path, img)\n",
    "        topath = os.path.join(test, cls, cls+'.'+str(i)+img[-4:])\n",
    "        shutil.copyfile(imgpath, topath)\n",
    "    num_test_examples += len(test_set)\n",
    "    print(\"processed %s test images for class %s\"%(len(test_set), cls))\n",
    "    \n",
    "    #Process validation data\n",
    "    for i,img in enumerate(validation_set):\n",
    "        imgpath = os.path.join(cls_path, img).strip()\n",
    "        topath = os.path.join(validation, cls, cls+'.'+str(i)+img[-4:])\n",
    "        shutil.copyfile(imgpath, topath)\n",
    "    num_validation_examples += len(validation_set)\n",
    "    print(\"processed %s validation images for class %s\"%(len(validation_set), cls))\n",
    "print('Training examples = %s, Testing examples = %s, Validation examples = %s'%(num_training_examples, \n",
    "                                                                                num_test_examples,\n",
    "                                                                                num_validation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
